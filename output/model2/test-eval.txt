$ env/scripts/python udpipe2_eval.py datasets/amharic2/amharic-ud-test.conllu output/model2/test-output.conllu --verbose
Metric     | Precision |    Recall |  F1 Score | AligndAcc
-----------+-----------+-----------+-----------+-----------
Tokens     |    100.00 |    100.00 |    100.00 |
Sentences  |    100.00 |    100.00 |    100.00 |
Words      |    100.00 |    100.00 |    100.00 |
UPOS       |     96.11 |     96.11 |     96.11 |     96.11
XPOS       |     95.26 |     95.26 |     95.26 |     95.26
UFeats     |     93.47 |     93.47 |     93.47 |     93.47
AllTags    |     91.16 |     91.16 |     91.16 |     91.16
Lemmas     |    100.00 |    100.00 |    100.00 |    100.00
UAS        |     94.63 |     94.63 |     94.63 |     94.63
LAS        |     84.00 |     84.00 |     84.00 |     84.00
CLAS       |     79.03 |     78.50 |     78.76 |     78.50
MLAS       |     70.81 |     70.33 |     70.57 |     70.33
BLEX       |     79.03 |     78.50 |     78.76 |     78.50